{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# Imports\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers \nimport tensorflow.keras.layers.experimental.preprocessing as preprocessing\nimport seaborn as sns\nimport os, cv2, json, warnings\nwarnings.simplefilter(\"ignore\")\nimport matplotlib.pyplot as plt\nimport IPython.display as display\nfrom matplotlib import gridspec\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.python.keras import optimizers\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\nfrom tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D, AveragePooling2D\nfrom tensorflow.python.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.python.keras import backend as K\n\ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])\nK.clear_session()\nWORK_DIR = '../input/cassava-leaf-disease-classification'\nos.listdir(WORK_DIR)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(os.path.join(WORK_DIR, \"train_images\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data\ntrain_labels = pd.read_csv(os.path.join(WORK_DIR, \"train.csv\"))\ntrain_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(os.path.join(WORK_DIR, \"label_num_to_disease_map.json\")) as file:\n    print(json.dumps(json.loads(file.read()), indent=4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nParameters\n\"\"\"\nBATCH_SIZE = 32\nEPOCHS = 20\nTARGET_SIZE = 226\nSTEPS = 10\nVALID_STEPS =5\nLR = 0.005\n\n# Reproducability\ndef set_seed(seed=32):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed()\n\n# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='magma')\nwarnings.filterwarnings(\"ignore\") # to clean up output cells\n\n\ntrain_labels.label = train_labels.label.astype('str')\n\ntrain_datagen = ImageDataGenerator(validation_split = 0.2,\n                                   rescale=1. / 255,\n                                   rotation_range = 20,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True,\n                                   vertical_flip = True,\n                                   fill_mode = 'nearest',\n                                   shear_range = 0.2,\n                                   height_shift_range = 0.1,\n                                   width_shift_range = 0.1)\n\ntest_datagen = ImageDataGenerator(validation_split = 0.2,\n                                  rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"training\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")\n\ntest_generator = test_datagen.flow_from_dataframe(train_labels ,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"validation\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nfig, ax = plt.subplots(figsize = (10, 4))\n\nfor i in ['top', 'right', 'left']:\n    ax.spines[i].set_visible(False)\nax.spines['bottom'].set_color('black')\n\nsns.countplot(train_labels.label, edgecolor = 'black',\n              palette = reversed(sns.color_palette(\"Spectral\", 5)))\nplt.xlabel('Classes', fontfamily = 'serif', size = 15)\nplt.ylabel('Count', fontfamily = 'serif', size = 15)\nplt.xticks(fontfamily = 'serif', size = 12)\nplt.yticks(fontfamily = 'serif', size = 12)\nax.grid(axis = 'y', linestyle = '--', alpha = 0.9)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the MobileNetV2 network, ensuring the head FC layer sets are\n# left off\n#baseModel = MobileNetV2(weights= None,input_shape=(TARGET_SIZE, TARGET_SIZE, 3), include_top=False,\n#\tinput_tensor=Input(shape=(TARGET_SIZE, TARGET_SIZE, 3)))\n#baseModel.load_weights('../input/mobilenetv2weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5')\n# construct the head of the model that will be placed on top of the\n# the base model\n#headModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(3, 3))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(991, activation=\"relu\")(headModel)\nheadModel = Dropout(0.3)(headModel)\nheadModel = Dense(991, activation=\"relu\")(headModel)\nheadModel = Dropout(0.4)(headModel)\nheadModel = Dense(5, activation=\"softmax\")(headModel)\n\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel_net_2 = Model(inputs=baseModel.input, outputs=headModel)\n\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the first training process\nfor layer in baseModel.layers:\n\tlayer.trainable = False\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_net_2 = Sequential()\n#model_net_2.add(Convolution2D(filters=32, kernel_size=5, padding =\"same\", input_shape=(TARGET_SIZE, TARGET_SIZE, 3), activation='relu'))\n#model_net_2.add(MaxPooling2D(pool_size=(3,3)))\n#cnn.add(Convolution2D(filters=64, kernel_size=3, padding =\"same\",activation='relu'))\n#cnn.add(AveragePooling2D(pool_size=(3,3)))\n\nmodel_net_2.add(Convolution2D(filters=128, kernel_size=3, padding =\"same\",activation='relu' , input_shape=(TARGET_SIZE, TARGET_SIZE, 3)))\nmodel_net_2.add(MaxPooling2D(pool_size=(3,3)))\n\nmodel_net_2.add(Flatten())\nmodel_net_2.add(Dense(991, activation='relu'))\nmodel_net_2.add(Dropout(0.3))\nmodel_net_2.add(Dense(991, activation='relu'))\nmodel_net_2.add(Dropout(0.4))\nmodel_net_2.add(Dense(5, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_net_2.compile(\n  optimizer=tf.keras.optimizers.SGD(learning_rate=LR, decay=LR / EPOCHS),\n  loss='sparse_categorical_crossentropy',\n  metrics=['sparse_categorical_accuracy'])\n\nmodel_net_2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_net_2.fit_generator(\n    train_generator,\n    steps_per_epoch=STEPS,\n    epochs=EPOCHS,  \n    validation_data=test_generator,  \n    validation_steps=VALID_STEPS)\n    #callbacks = [early_stop])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"model_net_2.save('Model_1Cov_1.h5')    \nmodel_net_2.save_weights('W_Model_1Cov_1.h5') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_training_curves( \n    history.history['loss'],\n    history.history['val_loss'], \n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212, \n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Custom train CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn = Sequential()\ncnn.add(Convolution2D(filters=32, kernel_size=5, padding =\"same\", input_shape=(TARGET_SIZE, TARGET_SIZE, 3), activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(3,3)))\n\n#cnn.add(Convolution2D(filters=64, kernel_size=3, padding =\"same\",activation='relu'))\n#cnn.add(AveragePooling2D(pool_size=(3,3)))\n\ncnn.add(Convolution2D(filters=128, kernel_size=3, padding =\"same\",activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(3,3)))\n\ncnn.add(Flatten())\ncnn.add(Dense(991, activation='relu'))\ncnn.add(Dropout(0.3))\ncnn.add(Dense(991, activation='relu'))\ncnn.add(Dropout(0.4))\ncnn.add(Dense(5, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn.compile(\n  optimizer=tf.keras.optimizers.Adam(learning_rate=LR, decay=LR / EPOCHS),\n  loss='sparse_categorical_crossentropy',\n  metrics=['sparse_categorical_accuracy'])\n\ncnn.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = cnn.fit_generator(\n    train_generator,\n    steps_per_epoch=STEPS,\n    epochs=EPOCHS,  \n    validation_data=test_generator,  \n    validation_steps=VALID_STEPS)\n    #callbacks = [early_stop])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn.save('CNN_Model_3.h5')    \ncnn.save_weights('CNN_W_Model_3.h5') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_training_curves( \n    hist.history['loss'],\n    hist.history['val_loss'], \n    'loss',\n    211,\n)\ndisplay_training_curves(\n    hist.history['sparse_categorical_accuracy'],\n    hist.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212, \n)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}